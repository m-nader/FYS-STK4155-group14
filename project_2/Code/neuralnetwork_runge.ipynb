{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643ae874",
   "metadata": {},
   "source": [
    "# Neural network to approximate Runge's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0883116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import autograd.numpy as np  # We need to use this numpy wrapper to make automatic differentiation work later\n",
    "from autograd import grad, elementwise_grad\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import (\n",
    "    PolynomialFeatures,\n",
    ")\n",
    "\n",
    "from functions import runge, OLS_parameters, MSE\n",
    "from functions import ReLU, ReLU_der, sigmoid, sigmoid_der, softmax, softmax_vec, mse_der\n",
    "from functions import MSE, NeuralNetwork, identity, identity_der, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52c19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 100\n",
    "# data set from project 1\n",
    "x = np.linspace(-1,1, n).reshape(-1,1)\n",
    "y = runge(x) + 0.1*np.random.normal(0,1, x.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "y_offset = y_train.mean()\n",
    "\n",
    "poly = PolynomialFeatures(degree=10)\n",
    "X_train = poly.fit_transform(x_train)\n",
    "X_test = poly.fit_transform(x_test)\n",
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# OLS\n",
    "beta = OLS_parameters(X_train_s, y_train)\n",
    "y_test_tilde = X_test_s @ beta + y_offset\n",
    "y_train_tilde = X_train_s @ beta + y_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f88ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output_sizes = [50, 1]\n",
    "activation_funcs = [sigmoid, identity]\n",
    "activation_ders = [sigmoid_der, identity_der]\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_s = scaler.transform(x_train)\n",
    "x_test_s = scaler.transform(x_test)\n",
    "inputs = x_train_s\n",
    "targets = y_train + y_offset\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    x_train_s,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    MSE,\n",
    "    mse_der,\n",
    ")\n",
    "\n",
    "NN.train_network(\n",
    "    epochs=100,\n",
    "    learning_rate=0.01,\n",
    "    minibatch_size=15,\n",
    "    momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e40c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_output_sizes = [50, 1]\n",
    "# activation_funcs = [sigmoid, identity]\n",
    "# activation_ders = [sigmoid_der, identity_der]\n",
    "\n",
    "# scaler.fit(x_train)\n",
    "# x_train_s = scaler.transform(x_train)\n",
    "# inputs = x_train_s\n",
    "# targets = y_train + y_offset\n",
    "\n",
    "# network_input_size = 1\n",
    "# layers = create_layers(network_input_size, layer_output_sizes)\n",
    "# train_network(inputs, layers, activation_funcs, activation_ders, targets, mse_der, learning_rate=0.01, epochs=100, minibatch_size=15)\n",
    "# train_network_cross(inputs, layers, activation_funcs, activation_ders, targets, learning_rate=0.01, epochs=100, minibatch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ff3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(predictions, targets):\n",
    "#     one_hot_predictions = np.zeros(predictions.shape)\n",
    "\n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         one_hot_predictions[i, np.argmax(prediction)] = 1\n",
    "#     return accuracy_score(one_hot_predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77aa0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m targets \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;241m+\u001b[39m y_offset\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m NN\u001b[38;5;241m.\u001b[39mpredict(x_test_s)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/FYS-STK4155-group14/project_2/Code/functions.py:111\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(predictions, targets)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions):\n\u001b[1;32m    110\u001b[0m     one_hot_predictions[i, np\u001b[38;5;241m.\u001b[39margmax(prediction)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fys-course/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/fys-course/lib/python3.10/site-packages/sklearn/metrics/_classification.py:359\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    358\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 359\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/fys-course/lib/python3.10/site-packages/sklearn/metrics/_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    108\u001b[0m             type_true, type_pred\n\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    113\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "targets = y_test + y_offset\n",
    "\n",
    "predictions = NN.predict(x_test_s)\n",
    "print(accuracy(predictions, targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fys-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
