{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730591cb",
   "metadata": {},
   "source": [
    "# Neural network categorising the MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c431c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "from functions import ReLU, ReLU_der, sigmoid, sigmoid_der, softmax, softmax_der, cross_entropy, cross_entropy_der, leaky_ReLU, leaky_ReLU_der\n",
    "from nn_class_classification import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c212eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = datasets.fetch_openml('mnist_784', version=1, as_frame=False, parser='liac-arff')\n",
    "\n",
    "X = mnist.data.astype(np.float32) / 255.0\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c0f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fe6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# One layer, 50 neurons, sigmoid activation function, plain gradient descent, no optimizations\n",
    "layer_output_sizes = [50, 10]\n",
    "activation_funcs = [ReLU, softmax]\n",
    "activation_ders = [ReLU_der, None]\n",
    "\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    X_train,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    cross_entropy,\n",
    "    cross_entropy_der,\n",
    ")\n",
    "\n",
    "\n",
    "NN.train_network_plain_gd(max_iter=1000, lr_method=\"ADAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5813a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8442857142857143\n"
     ]
    }
   ],
   "source": [
    "test_scores = NN.predict(X_test)\n",
    "test_predict = np.argmax(test_scores, axis=1)\n",
    "targets = y_test\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(targets, test_predict)\n",
    "print('Accuracy: ', accuracy)\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ba3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# One layer, 50 neurons, sigmoid activation function, plain gradient descent, no optimizations\n",
    "layer_output_sizes = [50, 50, 10]\n",
    "activation_funcs = [ReLU, ReLU, softmax]\n",
    "activation_ders = [ReLU_der, ReLU_der, None]\n",
    "\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    X_train,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    cross_entropy,\n",
    "    cross_entropy_der,\n",
    ")\n",
    "\n",
    "\n",
    "NN.train_network_plain_gd(max_iter=1000, lr_method=\"ADAM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dad64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50,50,10\n",
      "Accuracy:  0.8094285714285714\n"
     ]
    }
   ],
   "source": [
    "test_scores = NN.predict(X_test)\n",
    "test_predict = np.argmax(test_scores, axis=1)\n",
    "targets = y_test\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(targets, test_predict)\n",
    "print('50,50,10')\n",
    "print('Accuracy: ', accuracy)\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# One layer, 50 neurons, sigmoid activation function, plain gradient descent, no optimizations\n",
    "layer_output_sizes = [100, 10]\n",
    "activation_funcs = [leaky_ReLU, softmax]\n",
    "activation_ders = [leaky_ReLU_der, None]\n",
    "\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    X_train,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    cross_entropy,\n",
    "    cross_entropy_der,\n",
    "    L2=True\n",
    ")\n",
    "\n",
    "NN.train_network_plain_gd(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = NN.predict(X_test)\n",
    "test_predict = np.argmax(test_scores, axis=1)\n",
    "targets = y_test\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(targets, test_predict)\n",
    "print('100,10')\n",
    "print('Accuracy: ', accuracy)\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# One layer, 50 neurons, sigmoid activation function, plain gradient descent, no optimizations\n",
    "layer_output_sizes = [100,100, 10]\n",
    "activation_funcs = [leaky_ReLU, leaky_ReLU, softmax]\n",
    "activation_ders = [leaky_ReLU_der, leaky_ReLU_der, None]\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    X_train,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    cross_entropy,\n",
    "    cross_entropy_der,\n",
    "    L2=True\n",
    ")\n",
    "\n",
    "NN.train_network_plain_gd(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed449e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = NN.predict(X_test)\n",
    "test_predict = np.argmax(test_scores, axis=1)\n",
    "targets = y_test\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(targets, test_predict)\n",
    "print('100,100,10')\n",
    "print('Accuracy: ', accuracy)\n",
    "accuracies.append(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
