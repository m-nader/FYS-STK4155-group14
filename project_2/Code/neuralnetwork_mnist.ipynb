{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730591cb",
   "metadata": {},
   "source": [
    "# Neural network categorising the MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c431c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "from functions import ReLU, ReLU_der, sigmoid, sigmoid_der, softmax, softmax_der, cross_entropy, cross_entropy_der\n",
    "from nn_class import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c212eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = datasets.fetch_openml('mnist_784', version=1, as_frame=False, parser='liac-arff')\n",
    "\n",
    "X = mnist.data.reshape(-1, 28, 28).astype(np.float32) / 255.0\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ba3f76",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 654. GiB for an array with shape (56000, 28, 56000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m targets \u001b[38;5;241m=\u001b[39m y_train\n\u001b[1;32m     11\u001b[0m NN \u001b[38;5;241m=\u001b[39m NeuralNetwork(\n\u001b[1;32m     12\u001b[0m     X_train,\n\u001b[1;32m     13\u001b[0m     targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     cross_entropy_der,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network_plain_gd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m targets \u001b[38;5;241m=\u001b[39m y_test\n",
      "File \u001b[0;32m~/FYS-STK4155-group14/project_2/Code/nn_class.py:207\u001b[0m, in \u001b[0;36mNeuralNetwork.train_network_plain_gd\u001b[0;34m(self, learning_rate, max_iter, stopping_criteria, lr_method, delta, rho, beta1, beta2)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m    206\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 207\u001b[0m     layer_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     prev_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSProp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/FYS-STK4155-group14/project_2/Code/nn_class.py:96\u001b[0m, in \u001b[0;36mNeuralNetwork.backpropagation\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     92\u001b[0m W, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# For last layer we use cost derivative as dC_da(L) can be computed directly\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     dC_da \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost_der\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# elementwise multiply by activation derivative\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     dC_dz \u001b[38;5;241m=\u001b[39m (activation_der(z) \u001b[38;5;241m*\u001b[39m dC_da\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/FYS-STK4155-group14/project_2/Code/nn_class.py:65\u001b[0m, in \u001b[0;36mNeuralNetwork.cost_der\u001b[0;34m(self, predicts, targets)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcost_der\u001b[39m(\u001b[38;5;28mself\u001b[39m, predicts, targets):\n\u001b[0;32m---> 65\u001b[0m     cost_der \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost_der_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cost_der\n",
      "File \u001b[0;32m~/FYS-STK4155-group14/project_2/Code/functions.py:91\u001b[0m, in \u001b[0;36mcross_entropy_der\u001b[0;34m(predict, target)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcross_entropy_der\u001b[39m(predict, target):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m (\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m) \u001b[38;5;241m/\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 654. GiB for an array with shape (56000, 28, 56000) and data type float64"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# One layer, 50 neurons, sigmoid activation function, plain gradient descent, no optimizations\n",
    "layer_output_sizes = [50, 1]\n",
    "activation_funcs = [softmax, softmax]\n",
    "activation_ders = [softmax_der, softmax_der]\n",
    "\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "NN = NeuralNetwork(\n",
    "    X_train,\n",
    "    targets,\n",
    "    layer_output_sizes,\n",
    "    activation_funcs,\n",
    "    activation_ders,\n",
    "    cross_entropy,\n",
    "    cross_entropy_der,\n",
    ")\n",
    "\n",
    "NN.train_network_plain_gd(max_iter=100)\n",
    "\n",
    "targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5813a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fys-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
